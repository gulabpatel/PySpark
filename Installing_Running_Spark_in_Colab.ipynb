{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Installing_Running_Spark_in_Colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHtOhRFsU8pkejlV7I3lYn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVz48YG5GfCF"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "This installs Apache Spark 3.0.0, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J896xHwYU_zO"
      },
      "source": [
        "# innstall java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEsv25VTKAdU"
      },
      "source": [
        "# install findspark \n",
        "!pip install -q findspark"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48LOFn4aKnRB",
        "outputId": "4cffd096-f167-4861-aeb8-912c925f2c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /usr/lib/jvm/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NByg7XAQKvtc",
        "outputId": "4fc6546a-dc45-4f8d-9587-a78b07fc6ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U pyarrow"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pyarrow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJXJ7493GUWG"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrrQFfjmLQF7"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPq7h9CcYK8t"
      },
      "source": [
        "os.environ['PYSPARK_SUBMIT_ARGS']=\n",
        "spark.sparkConntext.addPyFile('./')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yvvnzznLrQG",
        "outputId": "60764134-e165-4449-eeae-7fd343be9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test the spark\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3, False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/session.py:378: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPqw8FjyYI1x"
      },
      "source": [
        "import sys, tempfile, urllib"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5CSckDrbuBF"
      },
      "source": [
        "import urllib.request"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmSzomftYqum"
      },
      "source": [
        "BASE_DIR = '/tmp'\n",
        "OUTPUT_FILE = os.path.join(BASE_DIR, 'credit_data.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhv5gnFOaZt4"
      },
      "source": [
        "credit_data = urllib.request.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data', OUTPUT_FILE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwDg1k6YpYk",
        "outputId": "a92a61f6-69a7-4ef2-85ed-7df59d0ddfed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /tmp"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blockmgr-59efbf98-0f35-4be7-85bf-00a0118c29e2\n",
            "credit_data.csv\n",
            "hsperfdata_root\n",
            "liblz4-java-3706817516286049092.so\n",
            "liblz4-java-3706817516286049092.so.lck\n",
            "spark-1eb482f3-240e-44e8-8dbe-85e27b661034\n",
            "spark-ab28a8ad-07f7-46c4-b020-75dbc0cfda40\n",
            "tmp6nif2clb\n",
            "tmpfr3to2eq\n",
            "tmpto5ddbz4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_hPmPl5b95J"
      },
      "source": [
        "credit_df = spark.read.option(\"inferSchema\",'true').csv(\"/tmp/credit_data.csv\", header=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJHTOK9OmLN7",
        "outputId": "4698c8ca-2489-4161-dc0b-7a79e3b10df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "credit_df.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "|_c0|  _c1|   _c2|_c3|_c4|_c5|_c6|  _c7|_c8|_c9|_c10|_c11|_c12| _c13| _c14|_c15|\n",
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "|  b|30.83|   0.0|  u|  g|  w|  v| 1.25|  t|  t|   1|   f|   g|00202|    0|   +|\n",
            "|  a|58.67|  4.46|  u|  g|  q|  h| 3.04|  t|  t|   6|   f|   g|00043|  560|   +|\n",
            "|  a|24.50|   0.5|  u|  g|  q|  h|  1.5|  t|  f|   0|   f|   g|00280|  824|   +|\n",
            "|  b|27.83|  1.54|  u|  g|  w|  v| 3.75|  t|  t|   5|   t|   g|00100|    3|   +|\n",
            "|  b|20.17| 5.625|  u|  g|  w|  v| 1.71|  t|  f|   0|   f|   s|00120|    0|   +|\n",
            "|  b|32.08|   4.0|  u|  g|  m|  v|  2.5|  t|  f|   0|   t|   g|00360|    0|   +|\n",
            "|  b|33.17|  1.04|  u|  g|  r|  h|  6.5|  t|  f|   0|   t|   g|00164|31285|   +|\n",
            "|  a|22.92|11.585|  u|  g| cc|  v| 0.04|  t|  f|   0|   f|   g|00080| 1349|   +|\n",
            "|  b|54.42|   0.5|  y|  p|  k|  h| 3.96|  t|  f|   0|   f|   g|00180|  314|   +|\n",
            "|  b|42.50| 4.915|  y|  p|  w|  v|3.165|  t|  f|   0|   t|   g|00052| 1442|   +|\n",
            "|  b|22.08|  0.83|  u|  g|  c|  h|2.165|  f|  f|   0|   t|   g|00128|    0|   +|\n",
            "|  b|29.92| 1.835|  u|  g|  c|  h|4.335|  t|  f|   0|   f|   g|00260|  200|   +|\n",
            "|  a|38.25|   6.0|  u|  g|  k|  v|  1.0|  t|  f|   0|   t|   g|00000|    0|   +|\n",
            "|  b|48.08|  6.04|  u|  g|  k|  v| 0.04|  f|  f|   0|   f|   g|00000| 2690|   +|\n",
            "|  a|45.83|  10.5|  u|  g|  q|  v|  5.0|  t|  t|   7|   t|   g|00000|    0|   +|\n",
            "|  b|36.67| 4.415|  y|  p|  k|  v| 0.25|  t|  t|  10|   t|   g|00320|    0|   +|\n",
            "|  b|28.25| 0.875|  u|  g|  m|  v| 0.96|  t|  t|   3|   t|   g|00396|    0|   +|\n",
            "|  a|23.25| 5.875|  u|  g|  q|  v| 3.17|  t|  t|  10|   f|   g|00120|  245|   +|\n",
            "|  b|21.83|  0.25|  u|  g|  d|  h|0.665|  t|  f|   0|   t|   g|00000|    0|   +|\n",
            "|  a|19.17| 8.585|  u|  g| cc|  h| 0.75|  t|  t|   7|   f|   g|00096|    0|   +|\n",
            "+---+-----+------+---+---+---+---+-----+---+---+----+----+----+-----+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GaZhhmBnUlP",
        "outputId": "1e39a3c2-3cda-4b37-eb3a-ce45d2b2e1e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "credit_df.count()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoaHJn0_nWsn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}